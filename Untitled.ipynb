{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82189890-b26b-4a53-971f-bed92999eb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. Top 5 Critical Issues (Frequency + Impact) ---\n",
      "Issues are ranked by volume (Frequency), showing their resolution time (Impact).\n",
      "                                          Issue 2-NPS  Total_Frequency  \\\n",
      "5                   Looking For Career Guidance (NPS)               21   \n",
      "0   Applied for jobs but no satisfactory outcome (...               19   \n",
      "1                   False Promise By Sales Team (NPS)               18   \n",
      "9         Projects & Assignment Related Concern (NPS)               18   \n",
      "11             Time Management Related Concerns (NPS)               18   \n",
      "\n",
      "    Avg_Resolution_Time_Days  \n",
      "5                   7.423161  \n",
      "0                   6.172624  \n",
      "1                   7.096008  \n",
      "9                   6.966296  \n",
      "11                  7.450820  \n",
      "\n",
      "--- 2. Resolution Time Patterns (Finding Bottlenecks) ---\n",
      "Showing top 5 slowest issues to identify high-impact, complex problems:\n",
      "                               Issue 2-NPS  Total_Frequency  \\\n",
      "3        Instructor Related Feedback (NPS)               14   \n",
      "6    Mentor Support Related Concerns (NPS)               17   \n",
      "11  Time Management Related Concerns (NPS)               18   \n",
      "5        Looking For Career Guidance (NPS)               21   \n",
      "2          Frequent Resume Rejection (NPS)               16   \n",
      "\n",
      "    Avg_Resolution_Time_Days  \n",
      "3                   7.899024  \n",
      "6                   7.661420  \n",
      "11                  7.450820  \n",
      "5                   7.423161  \n",
      "2                   7.329700  \n",
      "\n",
      "--- 3. Single Fix for Most Learners ---\n",
      "The single fix should target the highest volume issue: Looking For Career Guidance (NPS) (Total: 21 tickets).\n",
      "\n",
      "--- 4. Cross-Program vs. Program-Specific Problems ---\n",
      "Distribution of Top 5 Issues (Row Percentage):\n",
      "Program Name                                        AIML  Academy  DSML  \\\n",
      "Issue 2-NPS                                                               \n",
      "Applied for jobs but no satisfactory outcome (NPS)  42.1     31.6  15.8   \n",
      "False Promise By Sales Team (NPS)                   27.8     22.2  33.3   \n",
      "Looking For Career Guidance (NPS)                   23.8     28.6  28.6   \n",
      "Projects & Assignment Related Concern (NPS)          5.6     33.3  38.9   \n",
      "Time Management Related Concerns (NPS)              27.8     27.8  22.2   \n",
      "\n",
      "Program Name                                        DevOps  \n",
      "Issue 2-NPS                                                 \n",
      "Applied for jobs but no satisfactory outcome (NPS)    10.5  \n",
      "False Promise By Sales Team (NPS)                     16.7  \n",
      "Looking For Career Guidance (NPS)                     19.0  \n",
      "Projects & Assignment Related Concern (NPS)           22.2  \n",
      "Time Management Related Concerns (NPS)                22.2  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"Assignment_Cleaned.csv\")\n",
    "\n",
    "# 1. Standardize/Calculate Critical Analysis Columns\n",
    "# Combine separate columns into proper datetime objects\n",
    "df['Created Date/Time'] = pd.to_datetime(df['Created Date'] + ' ' + df['Created Time'], errors='coerce')\n",
    "df['Resolved Date/Time'] = pd.to_datetime(df['Resolved Date'] + ' ' + df['Resolved Time'], errors='coerce')\n",
    "\n",
    "# Calculate Resolution Time (Impact) in Days for analysis.\n",
    "df['Resolution Time (Days)'] = (df['Resolved Date/Time'] - df['Created Date/Time']).dt.total_seconds() / (3600 * 24)\n",
    "\n",
    "# Standardize the Issue Column Name for easy reference\n",
    "df = df.rename(columns={'Issue 2 - NPS': 'Issue 2-NPS'})\n",
    "\n",
    "# --- Issue Prioritization Analysis (Task 2.1) ---\n",
    "\n",
    "# Aggregate data by issue type to find both Frequency and Impact\n",
    "issue_analysis = df.groupby('Issue 2-NPS').agg(\n",
    "    # Frequency (Volume): Count of ALL tickets (open + resolved)\n",
    "    Total_Frequency=('Ticket No', 'count'),\n",
    "    # Impact (Efficiency): Average Resolution Time (only includes resolved tickets)\n",
    "    Avg_Resolution_Time_Days=('Resolution Time (Days)', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Sort by Frequency to identify the most common issues\n",
    "issue_analysis_freq_sorted = issue_analysis.sort_values(by='Total_Frequency', ascending=False)\n",
    "top_5_issues_list = issue_analysis_freq_sorted.head(5)['Issue 2-NPS'].tolist()\n",
    "\n",
    "\n",
    "# --- Print Analysis Outputs for Submission ---\n",
    "\n",
    "print(\"\\n--- 1. Top 5 Critical Issues (Frequency + Impact) ---\")\n",
    "print(\"Issues are ranked by volume (Frequency), showing their resolution time (Impact).\")\n",
    "print(issue_analysis_freq_sorted[['Issue 2-NPS', 'Total_Frequency', 'Avg_Resolution_Time_Days']].head(5))\n",
    "\n",
    "print(\"\\n--- 2. Resolution Time Patterns (Finding Bottlenecks) ---\")\n",
    "# Sort by Time to find the slowest issues, indicating complexity or cross-functional delays.\n",
    "issue_analysis_time_sorted = issue_analysis.sort_values(by='Avg_Resolution_Time_Days', ascending=False)\n",
    "print(\"Showing top 5 slowest issues to identify high-impact, complex problems:\")\n",
    "print(issue_analysis_time_sorted[['Issue 2-NPS', 'Total_Frequency', 'Avg_Resolution_Time_Days']].head(5))\n",
    "\n",
    "print(\"\\n--- 3. Single Fix for Most Learners ---\")\n",
    "# The highest frequency issue affects the largest number of users.\n",
    "single_fix_issue = issue_analysis_freq_sorted.iloc[0]\n",
    "print(f\"The single fix should target the highest volume issue: {single_fix_issue['Issue 2-NPS']} (Total: {int(single_fix_issue['Total_Frequency'])} tickets).\")\n",
    "\n",
    "print(\"\\n--- 4. Cross-Program vs. Program-Specific Problems ---\")\n",
    "# Analyze the distribution of the Top 5 issues across programs.\n",
    "df_top_5 = df[df['Issue 2-NPS'].isin(top_5_issues_list)]\n",
    "issue_program_percentage = pd.crosstab(\n",
    "    df_top_5['Issue 2-NPS'],\n",
    "    df_top_5['Program Name']\n",
    ").apply(lambda r: r / r.sum() * 100, axis=1).round(1)\n",
    "\n",
    "print(\"Distribution of Top 5 Issues (Row Percentage):\")\n",
    "print(issue_program_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6953792-5c71-4cef-bf39-e9c5d48b9892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. Agent Performance: Volume vs. Efficiency ---\n",
      "Top 10 Agents Ranked by Resolved Volume:\n",
      "       Assigned To  Resolved_Tickets  Avg_Resolution_Time_Days\n",
      "3      Jessica Kim                32                      6.55\n",
      "0       Amit Patel                18                      5.77\n",
      "5        Mike Chen                18                      7.75\n",
      "4   Lisa Rodriguez                17                      6.72\n",
      "6     Priya Sharma                16                      4.86\n",
      "7      Rohit Gupta                15                      6.04\n",
      "1  Carlos Martinez                14                      6.76\n",
      "2     David Wilson                13                      5.91\n",
      "9      Sneha Reddy                12                      8.85\n",
      "8    Sarah Johnson                11                      9.33\n",
      "\n",
      "--- 2. Ticket Volume Trend Analysis ---\n",
      "Weekly Ticket Creation Volume (First 10 Weeks):\n",
      "  Week Start Date  Ticket Volume\n",
      "0      2025-08-03             15\n",
      "1      2025-08-10             32\n",
      "2      2025-08-17             24\n",
      "3      2025-08-24             35\n",
      "4      2025-08-31             34\n",
      "5      2025-09-07             18\n",
      "6      2025-09-14             33\n",
      "7      2025-09-21             34\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Reconstruct the necessary analysis columns (Resolution Time is key for impact)\n",
    "df['Created Date/Time'] = pd.to_datetime(df['Created Date'] + ' ' + df['Created Time'], errors='coerce')\n",
    "df['Resolved Date/Time'] = pd.to_datetime(df['Resolved Date'] + ' ' + df['Resolved Time'], errors='coerce')\n",
    "\n",
    "# Calculate Resolution Time in Days (easier for management review than hours)\n",
    "df['Resolution Time (Days)'] = (df['Resolved Date/Time'] - df['Created Date/Time']).dt.total_seconds() / (3600 * 24)\n",
    "\n",
    "# Standardize the Issue Column Name\n",
    "df = df.rename(columns={'Issue 2 - NPS': 'Issue 2-NPS'})\n",
    "\n",
    "\n",
    "# --- 1. Team Performance Analysis (Resolution Efficiency) ---\n",
    "\n",
    "print(\"\\n--- 1. Agent Performance: Volume vs. Efficiency ---\")\n",
    "\n",
    "# Filter for only resolved tickets; we can't measure efficiency on open tickets.\n",
    "\n",
    "df_resolved_tickets = df[(df['Status'] == 'Complete') & (df['Assigned To'].str.strip() != 'Unassigned')].dropna(subset=['Assigned To'])\n",
    "\n",
    "# Group by agent to calculate performance metrics\n",
    "agent_performance_metrics = df_resolved_tickets.groupby('Assigned To').agg(\n",
    "    Resolved_Tickets=('Ticket No', 'count'),\n",
    "    Avg_Resolution_Time_Days=('Resolution Time (Days)', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Sort by Volume (most productive agents first)\n",
    "agent_performance_metrics = agent_performance_metrics.sort_values(by='Resolved_Tickets', ascending=False)\n",
    "agent_performance_metrics['Avg_Resolution_Time_Days'] = agent_performance_metrics['Avg_Resolution_Time_Days'].round(2)\n",
    "\n",
    "print(\"Top 10 Agents Ranked by Resolved Volume:\")\n",
    "print(agent_performance_metrics[['Assigned To', 'Resolved_Tickets', 'Avg_Resolution_Time_Days']].head(10))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n--- 2. Ticket Volume Trend Analysis ---\")\n",
    "\n",
    "weekly_demand_trends = df.set_index('Created Date/Time').resample('W')['Ticket No'].count().reset_index()\n",
    "weekly_demand_trends.columns = ['Week Start Date', 'Ticket Volume']\n",
    "\n",
    "print(\"Weekly Ticket Creation Volume (First 10 Weeks):\")\n",
    "print(weekly_demand_trends.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f771e6-8e3a-4cfe-a853-54cda4794a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Note: This code was executed previously to find common themes.\n",
    "\n",
    "# Define common noise words to filter out\n",
    "stop_words = set(['the', 'and', 'to', 'a', 'in', 'is', 'it', 'of', 'for', 'with', 'but', 'no', 'my', 'at', 'i', 'was', 'as', 'he', 'she', 'not', 'that', 'on', 'or', 'be', 'by', 'this', 'have', 'from', 'we', 'are', 'can', 'would', 'so', 'get', 'need', 'know', 'if', 'don', 'out', 'up', 'all', 'do', 'will', 'us', 'has', 'just', 'when', 'them', 'who', 'about', 'there', 'what', 'which', 'their', 'only', 'much', 'more', 'how', 'than', 'could',\n",
    "                  'resolution', 'resolved', 'ticket', 'issue', 'nps', 'feedback', 'concern', 'team', 'provided', 'related', 'best', 'practices', 'session', 'schedule', 'guidance', 'learner', 'program', 'course', 'academy', 'devops', 'dsml', 'aiml', 'sales', 'months', 'client', 'calls', 'within'])\n",
    "\n",
    "# Function to clean text and count words (omitted for brevity, but relies on Counter and re)\n",
    "def get_top_keywords(df, issue_name, stop_words):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c531393-ef00-4088-a9be-2e4deadda24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Core KPI Metrics for Dashboard Scorecard ---\n",
      "1. Total Ticket Volume (Demand): 225\n",
      "2. Median Resolution Time: 6.88 Days\n",
      "3. % Tickets Resolved within 48-Hour SLA: 8.2%\n",
      "4. Top 3 Issue Share of Voice: 25.8%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f6dd6d3-a1bc-4d66-9dd9-c769ccf26fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Core KPI Metrics for Dashboard Scorecard ---\n",
      "1. Total Ticket Volume (Demand): 225\n",
      "2. Median Resolution Time: 6.88 Days\n",
      "3. % Tickets Resolved within 48-Hour SLA: 8.2%\n",
      "4. Top 3 Issue Share of Voice: 25.8%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv(\"Assignment_Cleaned.csv\")\n",
    "\n",
    "# 1. Reconstruct combined Date/Time columns\n",
    "df['Created Date/Time'] = pd.to_datetime(df['Created Date'] + ' ' + df['Created Time'], errors='coerce')\n",
    "df['Resolved Date/Time'] = pd.to_datetime(df['Resolved Date'] + ' ' + df['Resolved Time'], errors='coerce')\n",
    "\n",
    "# 2. Calculate Resolution Time in Hours\n",
    "df['Resolution Time (Hours)'] = (df['Resolved Date/Time'] - df['Created Date/Time']).dt.total_seconds() / 3600\n",
    "df = df.rename(columns={'Issue 2 - NPS': 'Issue 2-NPS'})\n",
    "\n",
    "# --- Core KPI Calculation for Dashboard Scorecard ---\n",
    "\n",
    "# KPI 1: Total Demand (Volume)\n",
    "total_tickets = df['Ticket No'].count()\n",
    "\n",
    "# KPI 2: Median Resolution Time (Efficiency)\n",
    "median_resolution_time_days = round(df['Resolution Time (Hours)'].median() / 24, 2)\n",
    "\n",
    "# KPI 3: % Tickets Resolved within 48 Hours (SLA Adherence)\n",
    "df_resolved = df[df['Resolution Time (Hours)'].notna()]\n",
    "sla_adherence = (df_resolved['Resolution Time (Hours)'] <= 48).sum() / len(df_resolved)\n",
    "pct_sla_met = round(sla_adherence * 100, 1)\n",
    "\n",
    "# KPI 4: Top 3 Issue Share of Voice (Quality/Focus Area)\n",
    "top_3_issues_list = df['Issue 2-NPS'].value_counts().nlargest(3).index.tolist()\n",
    "top_3_tickets = df[df['Issue 2-NPS'].isin(top_3_issues_list)]['Ticket No'].count()\n",
    "top_3_share = round((top_3_tickets / total_tickets) * 100, 1)\n",
    "-\n",
    "print(\"\\n--- Core KPI Metrics for Dashboard Scorecard ---\")\n",
    "print(f\"1. Total Ticket Volume (Demand): {total_tickets}\")\n",
    "print(f\"2. Median Resolution Time: {median_resolution_time_days} Days\")\n",
    "print(f\"3. % Tickets Resolved within 48-Hour SLA: {pct_sla_met}%\")\n",
    "print(f\"4. Top 3 Issue Share of Voice: {top_3_share}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26584c-696a-4f7a-9fa1-d73b2ed64180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
